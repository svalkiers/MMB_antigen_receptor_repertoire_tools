{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART 2:** Preparing data for epitope annotation with TCRex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set the working directory to the repository directory\n",
    "os.chdir(\"/home/sebastiaan/PhD/Repositories/book_chapter/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will need the `pandas` library for handling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCRex has sets an upper limit of 50,000 to the amount of sequences that the user may upload. Therefore, files containing more than 50K sequences should be split into smaller chunks that satisfy the upload limit of the TCRex software.\n",
    "\n",
    "We will start out by writing a function that does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data in smaller files\n",
    "def split_data(\n",
    "    data: pd.DataFrame,\n",
    "    fn: str,\n",
    "    folder: str,\n",
    "    tcrex_limit: int = 50000\n",
    "    ):  \n",
    "    \"\"\"\n",
    "    Split a file containing TCR sequences into smaller files defined by a user given maximum number of sequences.\n",
    "    \n",
    "    Args:\n",
    "        - fn: name of the file that needs to be split\n",
    "        - folder: path to the directory were the splitted files need to be stored\n",
    "        - tcrex_limit: maximum number of sequences in the splitted files (default = 50K)\n",
    "    \"\"\"\n",
    "    for i, chunk_start in enumerate(range(0, data.shape[0], tcrex_limit), start = 1):\n",
    "        # Select chunk\n",
    "        data_chunk = data[chunk_start:chunk_start + tcrex_limit]\n",
    "        # Save chunk to target directory\n",
    "        data_chunk.to_csv(\n",
    "            os.path.join(folder, '_'.join([fn, str(i)]) +'.tsv'),\n",
    "            sep = '\\t',\n",
    "            index = False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will check every file to see whether it exceeds the TCRex data limit. If so, we will split the file into smaller chunks (of size 50,000) using the function we defined previously. In addition, we should rename the columns containing CDR3, V and J gene information so that they satisfy the TCRex input format. The following function takes 6 arguments: the path to the source files, the path to the output folder (where results should be stored), the name of the CDR3, V and J gene columns and the size of the chunk (50,000 by default = TCRex limit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_splitter(\n",
    "    source: str,\n",
    "    destination: str,\n",
    "    cdr3_colname: str,\n",
    "    vgene_colname: str,\n",
    "    jgene_colname: str,\n",
    "    chunk_size: int = 50000\n",
    "    ):\n",
    "    \n",
    "    # Dictionary containing the names of the columns that should be renamed\n",
    "    remap_cols = {\n",
    "        cdr3_colname : \"CDR3_beta\",\n",
    "        vgene_colname : \"TRBV_gene\",\n",
    "        jgene_colname : \"TRBJ_gene\"\n",
    "        }\n",
    "    \n",
    "    # If the parsed_data folder does not exist, create it\n",
    "    if not os.path.exists(destination):\n",
    "        os.mkdir(destination)\n",
    "\n",
    "    # List files in source folder\n",
    "    files = os.listdir(source)\n",
    "    # Loop over files and split them if they contain more than 50K TCRs\n",
    "    for fn in files:\n",
    "        # Read in every file with name fn and rename its columns\n",
    "        data = pd.read_csv(os.path.join(source, fn), sep = '\\t')\n",
    "        data = data.rename(columns = remap_cols)\n",
    "        # Calculate the number of TCRs in the file\n",
    "        nr_rows = data.shape[0]\n",
    "        # If the number of TCRs exceeds the TCRex limit, split the file fn in smaller files\n",
    "        if nr_rows > chunk_size:\n",
    "            print(f\"Splitting {fn}\")\n",
    "            new_folder = os.path.join(destination, fn.split('.')[0])\n",
    "            if not os.path.exists(new_folder):\n",
    "                os.mkdir(new_folder)\n",
    "            # Use the split_data function we defined previously to split the file\n",
    "            split_data(\n",
    "                data = data,\n",
    "                fn = fn,\n",
    "                tcrex_limit = chunk_size, \n",
    "                folder = new_folder\n",
    "                )\n",
    "        # If the number of TCRs does not exceed the TCRex limit, move the file to the new folder\n",
    "        else:\n",
    "            os.replace(\n",
    "                source = os.path.join(source, fn),\n",
    "                destination = os.path.join(destination, fn)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing left to do now is to run the function with the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting P1_0_clones.txt\n",
      "Splitting P1_15_clones.txt\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to collect all parsed (i.e. splitted) files\n",
    "indir = \"./data/examples\"\n",
    "outdir = \"./data/tcrex_in\"\n",
    "\n",
    "file_splitter(\n",
    "    source = indir,\n",
    "    destination = outdir,\n",
    "    cdr3_colname = \"junction_aa\",\n",
    "    vgene_colname = \"v_call\",\n",
    "    jgene_colname = \"j_call\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
