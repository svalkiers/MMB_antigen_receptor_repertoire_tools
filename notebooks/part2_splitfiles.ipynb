{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART 2:** Preparing data for epitope annotation with TCRex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set the working directory to the repository directory\n",
    "os.chdir(\"/home/sebastiaan/PhD/Repositories/book_chapter/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will need the `pandas` library for handling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCRex has sets an upper limit of 50,000 to the amount of sequences that the user may upload. Therefore, files containing more than 50K sequences should be split into smaller chunks that satisfy the upload limit of the TCRex software.\n",
    "\n",
    "We will start out by writing a function that does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split data in smaller files\n",
    "def split_data(\n",
    "    fn: str, \n",
    "    folder: str, \n",
    "    tcrex_limit: int = 50000\n",
    "    ):  \n",
    "    \"\"\"\n",
    "    Split a file containing TCR sequences into smaller files defined by a user given maximum number of sequences.\n",
    "    \n",
    "    Args:\n",
    "        - fn: name of the file that needs to be split\n",
    "        - folder: path to the directory were the splitted files need to be stored\n",
    "        - tcrex_limit: maximum number of sequences in the splitted files (default = 50K)\n",
    "    \"\"\"\n",
    "    for i, chunk_start in enumerate(range(0, nr_rows, tcrex_limit), start=1):\n",
    "        # Select chunk\n",
    "        data_chunk = data[chunk_start:chunk_start + tcrex_limit]\n",
    "        # Save chunk to target directory\n",
    "        data_chunk.to_csv(\n",
    "            os.path.join(folder, '_'.join([fn, str(i)]) +'.tsv'),\n",
    "            sep = '\\t',\n",
    "            index = False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will check every file to see whether it exceeds the TCRex data limit. If so, we will split the file into smaller chunks (of size 50,000) using the function we defined previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to collect all parsed (i.e. splitted) files\n",
    "parsed_data = \"../data/parsed_data\"\n",
    "origin_data = \"../data/examples\"\n",
    "\n",
    "# If the parsed_data folder does not exist, create it\n",
    "if not os.path.exists(parsed_data):\n",
    "    os.makedir(parsed_data)\n",
    "\n",
    "# Loop over files and split them if they contain more than 50K TCRs\n",
    "for fn in files:\n",
    "    # Read in every file with name fn\n",
    "    data = pd.read_csv(os.path.join(origin_data, fn), sep = '\\t')\n",
    "    # Calculate the number of TCRs in the file\n",
    "    nr_rows = data.shape[0]\n",
    "    # If the number of TCRs exceeds the TCRex limit, split the file fn in smaller files\n",
    "    if nr_rows > tcrex_limit:\n",
    "        new_folder = os.path.join(parsed_data, fn.split('.')[0])\n",
    "        if not os.path.exists(new_folder):\n",
    "            os.mkdir(new_folder)\n",
    "        # Use the split_data function we defined previously to split the file\n",
    "        split_data(\n",
    "            fn = fn, \n",
    "            tcrex_limit = tcrex_limit, \n",
    "            folder = new_folder\n",
    "        )\n",
    "    # If the number of TCRs does not exceed the TCRex limit, move the file to the new folder\n",
    "    else:\n",
    "        os.replace(\n",
    "            source = os.path.join(origin_data, fn),\n",
    "            destination = os.path.join(parsed_data, fn)\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
