{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06711bca-c666-48bf-bb84-1a6bc9c2109a",
   "metadata": {},
   "source": [
    "# **PART 3:** Concatenate TCRex files\n",
    "In part 2 we split the data into smaller chunks. This way we ensure the files satisfy the input limit set by the [TCRex](https://tcrex.biodatamining.be/) software. In this tutorial, we merge the results back together. In case you did not split the TCRex input file, you can skip this step and directly move to **PART 4: TCRex results & statistics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eeba45c-ee2b-4e6a-823f-8cef0b18f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set the working directory to the repository directory\n",
    "os.chdir(\"/home/sebastiaan/PhD/Repositories/book_chapter/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b7a6f80-82a9-4a87-b153-c5efb4a9048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4d9e0-edac-4eee-9164-4bcff98b4297",
   "metadata": {},
   "source": [
    "We start by defining two functions for processing the TCRex results. The first function will be used to read the data correctly. The second function will combine the different chunks originating from the same file back together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b74a82-2718-48d4-9f6c-c5bff8a26552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(folder, file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in a TCRex results file as a pandas dataframe. \n",
    "    Ignores meta data information preceded with a '#' sign.\n",
    "    \n",
    "    Args:\n",
    "    - folder: The folder where the TCRex results file is located\n",
    "    - file: The name of the TCRex results file\n",
    "    \"\"\"\n",
    "    return pd.read_csv(os.path.join(folder, file), sep = \"\\t\", comment = \"#\")\n",
    "\n",
    "\n",
    "def concatenate_data(indir, outdir):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatenate TCRex results from different files into one file.\n",
    "    \n",
    "    Args:\n",
    "    - indir: Path to the directory where the folder with the TCRex results files are located.\n",
    "    - outdir\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(indir)\n",
    "    name = os.path.basename(indir)\n",
    "        \n",
    "    # Concatenate all dataframes in the results list\n",
    "    all_results = pd.concat(\n",
    "        objs = [read_results(indir, fn) for fn in files]\n",
    "        )\n",
    "\n",
    "    # Save concatenated dataframe in a new folder\n",
    "    new_file = os.path.join(outdir, '.'.join([name,'tsv']))\n",
    "    \n",
    "    # Write results to a new file\n",
    "    all_results.to_csv(new_file, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4fd5f-a4fa-416d-91f7-6e7eb0c127b1",
   "metadata": {},
   "source": [
    "Now we can apply the `concatenate_data` function that we just wrote to combine the chunks from the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29a071-8d9d-45da-a83f-8f025e93c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data(\n",
    "    indir = './data/tcrex_out/P1_15',\n",
    "    outdir = './data/results/tcrex'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
