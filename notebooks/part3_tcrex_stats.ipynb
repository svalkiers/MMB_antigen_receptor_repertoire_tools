{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samenvoegen en statistieken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/sofiegielis/Documents/BIOMINA/cluster_bookchapter/tutorial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_results(folder, file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in a TCRex results file as a pandas dataframe.\n",
    "    \n",
    "    Args:\n",
    "    - folder: The folder where the TCRex results file is located\n",
    "    - file: The name of the TCRex results file\n",
    "    \"\"\"\n",
    "    \n",
    "    # When reading the data into a dataframe, omit the first 7 lines with meta info\n",
    "    results = pd.read_csv(os.path.join(folder,file),\n",
    "                              skiprows=[0, 1, 2, 3, 4, 5, 6], sep='\\t')\n",
    "    return results\n",
    "\n",
    "\n",
    "def concatenate_data(folder, name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatenate TCRex results from different files into one file.\n",
    "    \n",
    "    Args:\n",
    "    - folder: Path to the directory where the folder with the TCRex results files are located.\n",
    "    - name: Name of the folder holding all the TCRex results file that need to be concatenated.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder)\n",
    "    # Remove the hidden DS_store file if present\n",
    "    if '.DS_Store' in files:\n",
    "        files.remove('.DS_Store')\n",
    "        \n",
    "    # Collect data from all files in a list\n",
    "    # Emtpy list to collect all data\n",
    "    results = []\n",
    "    for fn in files:\n",
    "        # Read in file fn in dataframe\n",
    "        data = read_results(folder, fn)\n",
    "        # Add dataframe to the results list\n",
    "        results.append(data)\n",
    "    # Concatenate all dataframes in the results list \n",
    "    all_results = pd.concat(results) \n",
    "\n",
    "    # Save concatenated dataframe in a new folder\n",
    "    new_folder = os.path.join(base_dir,'results/parsed_results')\n",
    "    if not os.path.exists(new_folder):\n",
    "            os.mkdir(new_folder)\n",
    "    all_results.to_csv(os.path.join(new_folder,'.'.join([name,'tsv'])),\n",
    "                       sep='\\t', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data(os.path.join(base_dir,'results/test'),'filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification_rate(nr_identified, repertoire_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the percentage of epitope-specific TCRs in a repertoire.\n",
    "    \n",
    "    Args:\n",
    "    - nr_identified: The number of identified epitope-specific TCRs \n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    \n",
    "    \"\"\"\n",
    "    ir = (nr_identified/repertoire_size)*100\n",
    "    \n",
    "    return ir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as statistics\n",
    "\n",
    "\n",
    "def enrichment_analysis(nr_identified, repertoire_size, enrichment_threshold):\n",
    "    \n",
    "     \"\"\"\n",
    "     Calculate the p value of a one sided binomial test.\n",
    "     \n",
    "     Args:\n",
    "     - nr_identified:  The number of identified epitope-specific TCRs \n",
    "     - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "     - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "     \n",
    "     \"\"\"\n",
    "    \n",
    "     p_value = statistics.binom_test(x=nr_identified, n=repertoire_size,\n",
    "                                     p=enrichment_threshold, alternative='greater')\n",
    "     \n",
    "     return p_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the resuls\n",
    "results = pd.read_csv(os.path.join(base_dir,'results/parsed_results','test.tsv'), sep='\\t')\n",
    "\n",
    "# Calculate the number of identified epitope-specific TCRs \n",
    "nr_identified = results.shape[0]  \n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire_size = 100000\n",
    "\n",
    "# Calculate the identification metrics\n",
    "enrichment_analysis(nr_identified, repertoire_size, 0.001 )\n",
    "identification_rate(nr_identified, repertoire_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For multiple epitopes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(results, repertoire_size, enrichment_threshold):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the identification rate and enrichment analysis p value for every epitope in a TCRex results file.\n",
    "    \n",
    "    Args:\n",
    "    - results: Pandas DataFrame containing the TCRex results\n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # For every epitope, store the calculated metrics in a dictionary\n",
    "    metrics = {}\n",
    "    for epitope in set(results['epitope'].tolist()):\n",
    "        metrics[epitope] = {}\n",
    "        # Retrieve all TCRs specific for the epitope\n",
    "        epitope_data = results[results['epitope'] == epitope]\n",
    "        # Calculate the number of epitope-specific TCRs\n",
    "        nr_identified = epitope_data.shape[0]\n",
    "        # Calculate the required metrics\n",
    "        metrics[epitope]['identification_rate'] = identification_rate(nr_identified, repertoire_size)\n",
    "        metrics[epitope]['p_value'] = enrichment_analysis(nr_identified, repertoire_size, enrichment_threshold)\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identification_rate</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QYDPVAALF</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.848163e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QIKVRVKMV</th>\n",
       "      <td>0.14</td>\n",
       "      <td>4.484526e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YSEHPTFTSQY</th>\n",
       "      <td>0.41</td>\n",
       "      <td>1.041819e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLVPMVATV</th>\n",
       "      <td>27.13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPSINVHHY</th>\n",
       "      <td>0.13</td>\n",
       "      <td>6.317656e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTEHDTLLY</th>\n",
       "      <td>0.96</td>\n",
       "      <td>2.394793e-151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPRVTGGGAM</th>\n",
       "      <td>0.27</td>\n",
       "      <td>3.391162e-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             identification_rate        p_value\n",
       "QYDPVAALF                   0.16   1.848163e-14\n",
       "QIKVRVKMV                   0.14   4.484526e-12\n",
       "YSEHPTFTSQY                 0.41   1.041819e-50\n",
       "NLVPMVATV                  27.13   0.000000e+00\n",
       "IPSINVHHY                   0.13   6.317656e-11\n",
       "VTEHDTLLY                   0.96  2.394793e-151\n",
       "TPRVTGGGAM                  0.27   3.391162e-29"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the resuls\n",
    "results = read_results(os.path.join(base_dir,'results'),'multiple.tsv')\n",
    "# Calculate the identification rate and enrichment analysis p value\n",
    "metrics = calculate_metrics(results,10000,0.0001)\n",
    "# Organize the metrics in a dataframe\n",
    "metrics_df = pd.DataFrame.from_dict(metrics)\n",
    "# Transpose the dataframe\n",
    "metrics_df = metrics_df.T\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple testing correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "metrics_df['adjusted_p_value'] = multipletests(metrics_df['p_value'].tolist(), \n",
    "              method='fdr_bh', is_sorted=False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identification_rate</th>\n",
       "      <th>p_value</th>\n",
       "      <th>adjusted_p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QYDPVAALF</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.848163e-14</td>\n",
       "      <td>2.587428e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QIKVRVKMV</th>\n",
       "      <td>0.14</td>\n",
       "      <td>4.484526e-12</td>\n",
       "      <td>5.231947e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YSEHPTFTSQY</th>\n",
       "      <td>0.41</td>\n",
       "      <td>1.041819e-50</td>\n",
       "      <td>2.430911e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLVPMVATV</th>\n",
       "      <td>27.13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPSINVHHY</th>\n",
       "      <td>0.13</td>\n",
       "      <td>6.317656e-11</td>\n",
       "      <td>6.317656e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTEHDTLLY</th>\n",
       "      <td>0.96</td>\n",
       "      <td>2.394793e-151</td>\n",
       "      <td>8.381774e-151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPRVTGGGAM</th>\n",
       "      <td>0.27</td>\n",
       "      <td>3.391162e-29</td>\n",
       "      <td>5.934533e-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             identification_rate        p_value  adjusted_p_value\n",
       "QYDPVAALF                   0.16   1.848163e-14      2.587428e-14\n",
       "QIKVRVKMV                   0.14   4.484526e-12      5.231947e-12\n",
       "YSEHPTFTSQY                 0.41   1.041819e-50      2.430911e-50\n",
       "NLVPMVATV                  27.13   0.000000e+00      0.000000e+00\n",
       "IPSINVHHY                   0.13   6.317656e-11      6.317656e-11\n",
       "VTEHDTLLY                   0.96  2.394793e-151     8.381774e-151\n",
       "TPRVTGGGAM                  0.27   3.391162e-29      5.934533e-29"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
