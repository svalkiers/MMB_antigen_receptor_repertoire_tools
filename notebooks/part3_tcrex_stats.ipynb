{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PART 3:** TCRex results & statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set the working directory to the repository directory\n",
    "os.chdir(\"/home/sebastiaan/PhD/Repositories/book_chapter/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will need the `pandas` library for handling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(folder, file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in a TCRex results file as a pandas dataframe. \n",
    "    Ignores meta data information preceded with a '#' sign.\n",
    "    \n",
    "    Args:\n",
    "    - folder: The folder where the TCRex results file is located\n",
    "    - file: The name of the TCRex results file\n",
    "    \"\"\"\n",
    "    return pd.read_csv(os.path.join(folder, fn), sep = \"\\t\", comment = \"#\")\n",
    "\n",
    "\n",
    "def concatenate_data(folder, name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Concatenate TCRex results from different files into one file.\n",
    "    \n",
    "    Args:\n",
    "    - folder: Path to the directory where the folder with the TCRex results files are located.\n",
    "    - name: Name of the folder holding all the TCRex results file that need to be concatenated.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of all files in the folder\n",
    "    files = os.listdir(folder)\n",
    "        \n",
    "    # Concatenate all dataframes in the results list\n",
    "    all_results = pd.concat(\n",
    "        objs = [read_results(folder, fn) for fn in files]\n",
    "        )\n",
    "\n",
    "    # Save concatenated dataframe in a new folder\n",
    "    new_folder = '../results/parsed_results'\n",
    "    new_file = os.path.join(new_folder, '.'.join([name,'tsv']))\n",
    "    \n",
    "    # If new folder does not exist, create it\n",
    "    if not os.path.exists(new_folder):\n",
    "            os.mkdir(new_folder)\n",
    "    \n",
    "    # Write results to a new file\n",
    "    all_results.to_csv(new_file, sep = '\\t', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_data(os.path.join(base_dir,'results/test'),'filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identification_rate(nr_identified, repertoire_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the percentage of epitope-specific TCRs in a repertoire.\n",
    "    \n",
    "    Args:\n",
    "    - nr_identified: The number of identified epitope-specific TCRs \n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    \n",
    "    \"\"\"\n",
    "    return (nr_identified / repertoire_size) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichment_analysis(\n",
    "    nr_identified: int, \n",
    "    repertoire_size: int, \n",
    "    threshold: float = 0.001\n",
    "    ):\n",
    "    \n",
    "     \"\"\"\n",
    "     Calculate the p value of a one sided binomial test.\n",
    "     \n",
    "     Args:\n",
    "     - nr_identified:  The number of identified epitope-specific TCRs \n",
    "     - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "     - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "     \n",
    "     \"\"\" \n",
    "    return scipy.stats.binom_test(\n",
    "         x = nr_identified, \n",
    "         n = repertoire_size,\n",
    "         p = threshold,\n",
    "         alternative = 'greater'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the resuls\n",
    "results = pd.read_csv(os.path.join('../results/parsed_results','test.tsv'), sep = '\\t')\n",
    "\n",
    "# Calculate the number of identified epitope-specific TCRs \n",
    "nr_identified = results.shape[0]  \n",
    "\n",
    "# Define the repertoire size\n",
    "repertoire_size = 100000\n",
    "\n",
    "p = enrichment_analysis(nr_identified, repertoire_size) # p-value\n",
    "ir = identification_rate(nr_identified, repertoire_size) # identification rate\n",
    "\n",
    "# Calculate the identification metrics\n",
    "print(f\"p value: {p}\"\n",
    "print(f\"Identification rate: {ir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  0  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame([[0,1]], columns = [\"a\", \"b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For multiple epitopes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(results, repertoire_size, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the identification rate and enrichment analysis p value for every epitope in a TCRex results file.\n",
    "    \n",
    "    Args:\n",
    "    - results: Pandas DataFrame containing the TCRex results\n",
    "    - repertoire_size: The number of TCRs in the original repertoire, reported on the TCRex results page\n",
    "    - enrichment_threshold: Probability of success as defined in a binomial test.\n",
    "    \"\"\"\n",
    "    # For every epitope, store the calculated metrics in a dictionary\n",
    "    cols = [\"identification_rate\", \"p_value\"]\n",
    "    metrics = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for epitope in set(results['epitope'].tolist()):\n",
    "        \n",
    "        # Retrieve all TCRs specific for the epitope\n",
    "        epitope_data = results[results['epitope'] == epitope]\n",
    "        # Calculate the number of epitope-specific TCRs\n",
    "        nr_identified = epitope_data.shape[0]\n",
    "        \n",
    "        ir = identification_rate(nr_identified, repertoire_size)\n",
    "        p = enrichment_analysis(nr_identified, repertoire_size, threshold)\n",
    "        \n",
    "        metrics = pd.concat([metrics, pd.DataFrame([[ir, p]], columns = cols)])\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identification_rate</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QYDPVAALF</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.848163e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QIKVRVKMV</th>\n",
       "      <td>0.14</td>\n",
       "      <td>4.484526e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YSEHPTFTSQY</th>\n",
       "      <td>0.41</td>\n",
       "      <td>1.041819e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLVPMVATV</th>\n",
       "      <td>27.13</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPSINVHHY</th>\n",
       "      <td>0.13</td>\n",
       "      <td>6.317656e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTEHDTLLY</th>\n",
       "      <td>0.96</td>\n",
       "      <td>2.394793e-151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPRVTGGGAM</th>\n",
       "      <td>0.27</td>\n",
       "      <td>3.391162e-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             identification_rate        p_value\n",
       "QYDPVAALF                   0.16   1.848163e-14\n",
       "QIKVRVKMV                   0.14   4.484526e-12\n",
       "YSEHPTFTSQY                 0.41   1.041819e-50\n",
       "NLVPMVATV                  27.13   0.000000e+00\n",
       "IPSINVHHY                   0.13   6.317656e-11\n",
       "VTEHDTLLY                   0.96  2.394793e-151\n",
       "TPRVTGGGAM                  0.27   3.391162e-29"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the resuls\n",
    "results = read_results(os.path.join(base_dir,'results'), 'multiple.tsv')\n",
    "\n",
    "metrics_df = calculate_metrics(\n",
    "    results = results,\n",
    "    repertoire_size = 10000,\n",
    "    threshold = 0.0001\n",
    "    )\n",
    "\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple testing correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_adj = multipletests(\n",
    "    pvals = metrics_df.p_value, \n",
    "    method = 'fdr_bh', \n",
    "    is_sorted = False\n",
    "    )[1]\n",
    "\n",
    "metrics_df['adjusted_p_value'] = p_adj\n",
    "metrics_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
